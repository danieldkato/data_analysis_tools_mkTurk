{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "from data_analysis_tools_mkTurk.utils_meta import *\n",
    "from data_analysis_tools_mkTurk.utils_mkturk import *\n",
    "import pathlib as Path\n",
    "import numpy as np \n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from natsort import os_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/issa-locker/Data/West\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m monkey \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      6\u001b[0m date \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m20230914\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 8\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[43mget_recording_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmonkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m n_recordings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_path)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(n_recordings, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m recordings found\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/mnt/smb/locker/issa-locker/users/Dan/code/data_analysis_tools_mkTurk/utils_meta.py:16\u001b[0m, in \u001b[0;36mget_recording_path\u001b[0;34m(base_data_path, monkey, date, depth)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_recording_path\u001b[39m(base_data_path, monkey, date,depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;66;03m# given the base data path, monkey, and date,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# returns the filepath where the spikeglx binary files are stored\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(Path\u001b[38;5;241m.\u001b[39mPath(base_data_path,monkey))\n\u001b[0;32m---> 16\u001b[0m     long_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmonkey\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m*\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     sub_lists \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mwalk(long_path) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(Path\u001b[38;5;241m.\u001b[39mPath(x[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mparents)\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(Path\u001b[38;5;241m.\u001b[39mPath(base_data_path)\u001b[38;5;241m.\u001b[39mparents) \u001b[38;5;241m==\u001b[39mdepth]\n\u001b[1;32m     19\u001b[0m     filepath \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# SET PATHS, RECORDING INFO\n",
    "#base_data_path = Path.Path(r'Z:\\Data')\n",
    "base_data_path = Path.Path('/Volumes/issa-locker/Data')\n",
    "\n",
    "monkey = 'West'\n",
    "date = '20240724'\n",
    "\n",
    "data_path = get_recording_path(base_data_path, monkey, date)\n",
    "\n",
    "n_recordings = len(data_path)\n",
    "print(n_recordings, ' recordings found')\n",
    "if n_recordings > 1:\n",
    "    data_ind = input('multiple recording sessions. Please select a number between 0 and' + str(len(data_path)-1))  # waiting for user input\n",
    "    data_path = Path.Path(data_path[int(data_ind)])\n",
    "else:\n",
    "    data_path = Path.Path(data_path[0])\n",
    "penetration = data_path.relative_to(base_data_path/monkey).as_posix().split('/')[0]\n",
    "print(data_path)\n",
    "\n",
    "print('\\nData path found: '+ str(data_path.exists()))\n",
    "\n",
    "# meta_iter = data_path.glob('*ap.meta')\n",
    "# bin_iter = data_path.glob('*ap.bin')   \n",
    "# meta_path = next(meta_iter)\n",
    "# bin_path = next(bin_iter) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get trig \n",
    "trig_path = data_path / 'imec_trig'\n",
    "print(trig_path)\n",
    "trig_on, trig_off = np.load(trig_path / 'trig_ind.npy')\n",
    "print(len(trig_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# behavior files in the data path \n",
    "\n",
    "behav_file_list_orig = os_sorted(Path.Path(base_data_path, monkey, penetration).glob('*.json'))\n",
    "print('Number of behavior files in the data path: ', len(behav_file_list_orig)) \n",
    "for i, b_f in enumerate(behav_file_list_orig):\n",
    "    m = json.load(open(b_f, 'rb'))\n",
    "    n_trials_mk_prepared = len(m['TRIALEVENTS']['Sample']['0'])\n",
    "    if len(m['TRIALEVENTS']['TSequenceActualClip']) >  0:\n",
    "        n_trials_mk_shown = len(m['TRIALEVENTS']['TSequenceActualClip']['0'])\n",
    "    else:\n",
    "        n_trials_mk_shown = 0 \n",
    "    behav_file_list_orig[i] = b_f.as_posix()\n",
    "    print(b_f.stem, n_trials_mk_prepared, n_trials_mk_shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(trig_on) > 1 and len(behav_file_list_orig) > 0:\n",
    "    save_out_root_path = '/Volumes/issa-locker/users/Younah/ephys/' + monkey\n",
    "    save_out_path = Path.Path(save_out_root_path, penetration)\n",
    "\n",
    "    if not os.path.exists(save_out_path):\n",
    "        os.mkdir(save_out_path)\n",
    "        print('creating save out folder')\n",
    "    else:\n",
    "        print('path exists')\n",
    "\n",
    "    if n_recordings> 1:\n",
    "        save_out_path = Path.Path(save_out_root_path, penetration, data_path.parts[len(data_path.parts)-2])\n",
    "\n",
    "    print(save_out_path)\n",
    "    os.makedirs(save_out_path, exist_ok=True)\n",
    "else:\n",
    "    print('Skip this recording session as there''s no trigger saved or behavior files not in the path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filecode(filecode_ind, len_filecode,out_list):\n",
    "    if len(filecode_ind) > len_filecode and len(filecode_ind) % len_filecode == 0:\n",
    "        # chunk by 6 \n",
    "        for i in range(0, len(filecode_ind), len_filecode):  \n",
    "            out_list.append(filecode_ind[i:i+len_filecode])\n",
    "    elif len(filecode_ind) == 6:\n",
    "        out_list.append(filecode_ind)\n",
    "    elif len(filecode_ind) > len_filecode: # if the detected \n",
    "        out_list.append(filecode_ind[len(filecode_ind)-len_filecode:len(filecode_ind)])\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "Fs = 30000\n",
    "len_filecode = 6\n",
    "max_trig_dur =300# digit (9 +1) * 10ms # change this value for earlier files. After 10/04/2023, 150 seems fine\n",
    "trig_dur = (trig_off - trig_on) /Fs * 1000 # ms\n",
    "ind = np.where(trig_dur <=max_trig_dur)[0] \n",
    "\n",
    "filecodes_ind_imec_possible= []\n",
    "for k, g in groupby(enumerate(ind), lambda ix : ix[0] -ix[1]):\n",
    "    filecode_ind = list(map(itemgetter(1), g))\n",
    "    print(filecode_ind, len(filecode_ind))\n",
    "    filecodes_ind_imec_possible = get_filecode(filecode_ind,len_filecode, filecodes_ind_imec_possible)\n",
    "print( f'{len(filecodes_ind_imec_possible)}' + ' possible filecodes found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecodes_imec = []\n",
    "scs_ind_imec = []\n",
    "n_scs_imec = []\n",
    "filecodes_ind_imec = []\n",
    "\n",
    "for i, filecode_ind in enumerate(filecodes_ind_imec_possible):\n",
    "    assert len(filecode_ind) == len_filecode, f'filecode length is not {len_filecode}'\n",
    "\n",
    "    filecode_dur = trig_dur[filecode_ind]\n",
    "    # sc_ind corresponds to indices of sample command triggers followed by a filecode \n",
    "    if i == len(filecodes_ind_imec_possible) -1: \n",
    "        sc_ind = np.arange(filecode_ind[len_filecode-1]+1, len(trig_dur)) # sample commands followed by the last filecode within a session\n",
    "    else:\n",
    "        sc_ind = np.arange(filecode_ind[len_filecode-1]+1, filecodes_ind_imec_possible[i+1][0])\n",
    "\n",
    "    # number of sample commands or number of initated trials\n",
    "    n_scs = len(sc_ind)\n",
    "\n",
    "    # converting the digital filecode to timestamps which should match the name of the behavior file \n",
    "    f_convert =[round(f/10-1) for f in filecode_dur]\n",
    "    f_convert = [0 if x<0 else x for x in f_convert]\n",
    "\n",
    "    filecode = str(f_convert[0]) + str(f_convert[1]) + '_' + \\\n",
    "    str(f_convert[2]) + str(f_convert[3]) + '_' + \\\n",
    "    str(f_convert[4]) + str(f_convert[5]) \n",
    "\n",
    "    print(i, 'start ind: ', filecode_ind[0],'filecode: ', filecode, '# of sample commands: ', n_scs)\n",
    "    filecodes_imec.append(filecode)\n",
    "    scs_ind_imec.append(sc_ind)\n",
    "    n_scs_imec.append(n_scs)\n",
    "    filecodes_ind_imec.append(filecode_ind)\n",
    "\n",
    "filecodes_ind_imec = np.array(filecodes_ind_imec)\n",
    "scs_ind_imec = np.array(scs_ind_imec)\n",
    "n_scs_imec = np.array(n_scs_imec)\n",
    "filecodes_imec = np.array(filecodes_imec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are some cases where the first sample command is fired before the filecode. \n",
    "# In this case, there is a very short latency between the onest of the filecode and the offset of the first sample command \n",
    "# it's likely that this first sample command was grouped to the previous file as the last sample command \n",
    "\n",
    "for idx,(filecode, filecode_ind, scs_ind) in enumerate(zip(filecodes_imec, filecodes_ind_imec,scs_ind_imec)):\n",
    "\n",
    "    if idx > 0 and n_scs_imec[idx-1] > 0:\n",
    "        t_diff = (trig_on[filecode_ind[0]] - trig_off[scs_ind_imec[idx-1][len(scs_ind_imec[idx-1])-1]]) /Fs * 1000\n",
    "        print(idx, t_diff)\n",
    "        if t_diff < 200: # less than 100ms or some small number\n",
    "            print(filecode)\n",
    "            prev_list= scs_ind_imec[idx-1]\n",
    "            scs_ind = np.insert(scs_ind, 0,prev_list[len(prev_list)-1])\n",
    "            scs_ind_imec[idx] = scs_ind\n",
    "            n_scs_imec[idx] = len(scs_ind)\n",
    "            scs_ind_imec[idx-1] = prev_list[0:len(prev_list)-1]\n",
    "            n_scs_imec[idx-1] = n_scs_imec[idx-1] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,(filecode, filecode_ind, scs_ind, n_scs) in enumerate(zip(filecodes_imec, filecodes_ind_imec, scs_ind_imec, n_scs_imec)):\n",
    "    print(i, 'filecode: ', filecode, ' # of sample commands: ', n_scs, len(scs_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_20_02_West.json\n",
      "# of mkturk trials:  217\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "2 17_29_06\n",
      "# of scs:  208\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_29_06_West.json\n",
      "# of mkturk trials:  208\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "3 101_71_47\n",
      "# of scs:  0\n",
      "No corresponding behavior file that matches with filecode 101_71_47 from imec\n",
      "\n",
      "\n",
      "4 38_38_38\n",
      "# of scs:  205\n",
      "No corresponding behavior file that matches with filecode 38_38_38 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_38_38_West.json\n",
      "# of mkturk trials:  206\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "5 17_59_08\n",
      "# of scs:  204\n",
      "No corresponding behavior file that matches with filecode 17_59_08 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_48_08_West.json\n",
      "# of mkturk trials:  204\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "6 17_58_02\n",
      "# of scs:  204\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_58_02_West.json\n",
      "# of mkturk trials:  204\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "7 28_07_49\n",
      "# of scs:  256\n",
      "No corresponding behavior file that matches with filecode 28_07_49 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_07_49_West.json\n",
      "# of mkturk trials:  255\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "8 18_21_58\n",
      "# of scs:  203\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_21_58_West.json\n",
      "# of mkturk trials:  203\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "9 18_32_28\n",
      "# of scs:  399\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_32_28_West.json\n",
      "# of mkturk trials:  399\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "10 18_54_22\n",
      "# of scs:  206\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_54_22_West.json\n",
      "# of mkturk trials:  206\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "11 19_16_34\n",
      "# of scs:  213\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_16_34_West.json\n",
      "# of mkturk trials:  213\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "12 19_38_15\n",
      "# of scs:  224\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_38_15_West.json\n",
      "# of mkturk trials:  224\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "13 19_53_06\n",
      "# of scs:  226\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_53_06_West.json\n",
      "# of mkturk trials:  225\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "14 20_06_52\n",
      "# of scs:  126\n",
      "No corresponding behavior file that matches with filecode 20_06_52 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T20_06_42_West.json\n",
      "# of mkturk trials:  126\n",
      "RewardStage :  1\n"
     ]
    }
   ],
   "source": [
    "# Matching behavior file to imec filecode \n",
    "\n",
    "behav_file_list = []\n",
    "behav_file_list_idx = [-1]\n",
    "filecodes_imec_to_analyze = []\n",
    "scs_ind_imec_to_analyze = []\n",
    "n_scs_imec_to_analyze = []\n",
    "filecodes_ind_imec_to_analyze = []\n",
    "for i, (f, n_scs, scs_ind, filecodes_ind) in enumerate(zip(filecodes_imec, n_scs_imec,scs_ind_imec,filecodes_ind_imec)):\n",
    "    print('\\n')\n",
    "    print(i, f)\n",
    "    print('# of scs: ', n_scs)\n",
    "    \n",
    "    behav_file = os_sorted(Path.Path(base_data_path, monkey, penetration).glob('*' + f + '*.json'))\n",
    "    if len(behav_file) > 0:\n",
    "        m = json.load(open(behav_file[0].as_posix(),'rb'))\n",
    "        if len(m['TRIALEVENTS']['TSequenceActualClip']) >  0:\n",
    "            n_trials_mk = len(m['TRIALEVENTS']['TSequenceActualClip']['0'])\n",
    "        else:\n",
    "            n_trials_mk = 0 \n",
    "\n",
    "        print('matching behavior file found')\n",
    "        print('matched with' , behav_file[0].as_posix())\n",
    "        print('# of mkturk trials: ', n_trials_mk)\n",
    "        print('RewardStage : ', m['TASK']['RewardStage'])\n",
    "\n",
    "        behav_file_list.append(behav_file[0].as_posix())\n",
    "        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == behav_file[0].as_posix())[0])\n",
    "        filecodes_imec_to_analyze.append(f)\n",
    "        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "        n_scs_imec_to_analyze.append(n_scs)\n",
    "        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "    else:\n",
    "        print(f'No corresponding behavior file that matches with filecode {f} from imec' )\n",
    "\n",
    "        # if there exists a mkturk file that matches almost all of the filecodes\n",
    "        for b_f_idx, b_f in enumerate(behav_file_list_orig):\n",
    "            if b_f not in behav_file_list and b_f_idx > max(behav_file_list_idx):\n",
    "                m = json.load(open(b_f,'rb'))\n",
    "                if len(m['TRIALEVENTS']['TSequenceActualClip']) >  0:\n",
    "                    n_trials_mk = len(m['TRIALEVENTS']['TSequenceActualClip']['0'])\n",
    "                else:\n",
    "                    n_trials_mk = 0 \n",
    "\n",
    "                file_time = Path.Path(b_f).stem.split('T')[1].split('_' + monkey)[0]\n",
    "                file_time_txt = file_time.split('_')\n",
    "                file_time_hour = file_time_txt[0]\n",
    "                file_time_minute = file_time_txt[1]\n",
    "                file_time_second = file_time_txt[2]\n",
    "\n",
    "                f_txt = f.split('_')\n",
    "                f_hour = f_txt[0]\n",
    "                f_minute = f_txt[1]\n",
    "                f_second = f_txt[2]\n",
    "\n",
    "                hour_diff = abs(int(file_time_hour) - int(f_hour))\n",
    "                minute_diff = abs(int(file_time_minute) - int(f_minute))\n",
    "                second_diff = abs(int(file_time_second) - int(f_second))\n",
    "                \n",
    "                diff_all = np.array((hour_diff,minute_diff,second_diff))\n",
    "\n",
    "                str_match =0\n",
    "\n",
    "                for t_str_count in range(8):\n",
    "                    if file_time[t_str_count] == f[t_str_count]:\n",
    "                        str_match += 1\n",
    "\n",
    "                if sum(diff_all) <=3 or len(np.where(diff_all == 0)[0]) == 2 or str_match >=6:\n",
    "                #if str_match >=6: # you can relax this threshold by making this number smaller\n",
    "                    print('filecode is defective but matches most of the datetime string in the behavior file')\n",
    "                    print('matched with' , b_f)\n",
    "                    print('# of mkturk trials: ', n_trials_mk)\n",
    "                    print('RewardStage : ', m['TASK']['RewardStage'])\n",
    "                    if n_scs == 0 and m['TASK']['RewardStage'] == 0:\n",
    "                        behav_file_list.append(b_f)\n",
    "                        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == b_f)[0])\n",
    "                        filecodes_imec_to_analyze.append(f)\n",
    "                        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "                        n_scs_imec_to_analyze.append(n_scs)\n",
    "                        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "                        break \n",
    "                    elif abs(n_scs - n_trials_mk) < 7:\n",
    "                        behav_file_list.append(b_f)\n",
    "                        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == b_f)[0])\n",
    "                        filecodes_imec_to_analyze.append(f)\n",
    "                        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "                        n_scs_imec_to_analyze.append(n_scs)\n",
    "                        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "                        break \n",
    "                    else:\n",
    "                        print('# of sc and # of mk trials don''t match up')\n",
    "                        break\n",
    "                else:\n",
    "\n",
    "                    if n_trials_mk >= n_scs -2 and n_trials_mk <= n_scs + 2 and n_scs !=0: # this might happen for earlier files \n",
    "\n",
    "                        print('no string matched but the number of sample command triggers seem to match the number of mkturk trials')\n",
    "                        print('# of mkturk trials: ', n_trials_mk)\n",
    "                        print('matched with' , b_f)\n",
    "                        print('RewardStage : ', m['TASK']['RewardStage'])\n",
    "\n",
    "                        behav_file_list.append(b_f)\n",
    "                        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == b_f)[0])\n",
    "                        filecodes_imec_to_analyze.append(f)\n",
    "                        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "                        n_scs_imec_to_analyze.append(n_scs)\n",
    "                        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(behav_file_list) == len(n_scs_imec_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(behav_file_list_orig) - len(behav_file_list), ' behavior files are unmatched \\n')\n",
    "unmatched_behav_file = list(set(behav_file_list_orig) - set(behav_file_list))\n",
    "\n",
    "for b_f in unmatched_behav_file:\n",
    "    print(b_f)\n",
    "    m = json.load(open(b_f,'rb'))\n",
    "    print('RewardStage : ', m['TASK']['RewardStage'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can either try to find triggers that belong to this remaining behavior file \n",
    "#  or skip it if it's a calibration file \n",
    "\n",
    "# of trigs unaccounted for \n",
    "print(len(trig_on) - (np.sum(n_scs_imec_to_analyze) + len_filecode * len(filecodes_imec_to_analyze)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stims_sess = 0 \n",
    "n_trials_sess = 0\n",
    "data_dict_all = dict()\n",
    "for idx, (behav_file, scs_ind, n_scs,filecode_ind) in enumerate(zip(behav_file_list,scs_ind_imec_to_analyze, n_scs_imec_to_analyze,filecodes_ind_imec_to_analyze)):\n",
    "    print(behav_file)\n",
    "    # skip calibration files\n",
    "    m = json.load(open(behav_file,'rb'))\n",
    "\n",
    "    if m['TASK']['RewardStage'] == 0:\n",
    "        print('calibration file. removing it from further analysis')\n",
    "    else:\n",
    "        if len(m['TASK']['ImageBagsSample']) != len( m['SCENES']['SampleScenes']):\n",
    "            print('ImageBagSample and number of scenefiles don''t match. skip this behavior file')\n",
    "            continue\n",
    "\n",
    "        data_dict  = create_data_mat(behav_file)\n",
    "        print(m['TASK']['ImageBagsSample'])\n",
    "\n",
    "        sc_off_mk =np.array(m['TRIALEVENTS']['SampleCommandOffReturnTime'],dtype=float)\n",
    "        sc_on_mk = np.array(m['TRIALEVENTS']['SampleCommandReturnTime'],dtype=float)\n",
    "\n",
    "        if 'NRSVPMax' in m['TASK'].keys():\n",
    "            n_rsvp = max(m['TASK']['NRSVP'], m['TASK']['NRSVPMax'])\n",
    "        else:\n",
    "            n_rsvp = m['TASK']['NRSVP'] \n",
    "\n",
    "        trig_on_time = trig_on[scs_ind]/Fs \n",
    "        trig_off_time = trig_off[scs_ind]/Fs \n",
    "        trig_dur = trig_off_time - trig_on_time\n",
    "\n",
    "        if len(sc_on_mk) != len(sc_off_mk):\n",
    "            print('mkturk behavior file has mismatched sample command on and off ')\n",
    "            if sc_on_mk[0] < sc_off_mk[0] and len(sc_on_mk) > len(sc_off_mk):\n",
    "                sc_off_mk = np.concatenate((sc_off_mk,np.nan * np.ones(len(sc_on_mk) - len(sc_off_mk))))\n",
    "                \n",
    "        sc_dur_mk =sc_off_mk - sc_on_mk\n",
    "        n_trials_mk = len(sc_dur_mk)\n",
    "\n",
    "        print('# of trials from mkturk file :', n_trials_mk, '\\n'\n",
    "            '# of imec triggers : ', n_scs)\n",
    "        \n",
    "        if n_trials_mk <= 10 and n_scs <= 10:\n",
    "            print('two few trials. Removing it from further analysis')\n",
    "        else:   \n",
    "            # compare number of triggers from imec file and n_trials_mk\n",
    "            # if they mismatch, they usually mismatch by 1\n",
    "            mean = np.mean(trig_dur)\n",
    "            sd = np.std(trig_dur)\n",
    "            print('mean trig dur: ', mean, 'sd: ', sd)\n",
    "            \n",
    "            if n_trials_mk == n_scs: \n",
    "                print('# of mkturk trials matches # of imec trigs')\n",
    "                print(np.nansum(np.abs(sc_dur_mk/1000 - trig_dur)))  # this number should be small but sometimes mkturk SampleCommandOffReturnTime is weird\n",
    "                #print(trig_dur, sc_dur_mk)\n",
    "            \n",
    "            if n_trials_mk > n_scs: # more mkturk trials than imec sample commands\n",
    "                print('more mkturk trials than imec trigs')\n",
    "                n_diff= n_trials_mk - n_scs\n",
    "                t_diff_first = np.nansum(np.abs(sc_dur_mk[0:n_scs]/1000 - trig_dur))\n",
    "                t_diff_last = np.nansum(np.abs(sc_dur_mk[n_diff:n_trials_mk]/1000-trig_dur))\n",
    "                print(f'first {n_diff} mkturk trials : ', sc_dur_mk[0:n_diff], f' last {n_diff} mkturk trials: ', sc_dur_mk[n_scs:n_trials_mk])\n",
    "                print(f'aligned to the first {n_scs} mkturk trials: ', t_diff_first, f' aligned to the last {n_scs} mkturk trials: ', t_diff_last)\n",
    "                \n",
    "                if t_diff_first > 5 and t_diff_last > 5:\n",
    "                    print('difference is too big on both ends. Check trig_dur and sc_dur_mk. If trig_dur is fine, proceed')\n",
    "                    #print('imec trig : ', trig_dur, 'mkturk time : ', sc_dur_mk/1000)\n",
    "                    print(len(np.where(sc_dur_mk <0)[0]), ' negative sc durations in mkturk file') \n",
    "\n",
    "                if t_diff_first < t_diff_last:\n",
    "                    # adds nan value at the end of imec trigger\n",
    "                    print('adds nan values at the end of imec trigger')\n",
    "                    trig_on_time = np.concatenate((trig_on_time,np.nan* np.ones(n_diff)))\n",
    "                    trig_off_time = np.concatenate((trig_off_time,np.nan* np.ones(n_diff)))\n",
    "                else:\n",
    "                    # adds nan value at the beginning of imec trigger\n",
    "                    print('adds nan values at the beginning of imec trigger')\n",
    "                    trig_on_time = np.concatenate((np.nan* np.ones(n_diff), trig_on_time))\n",
    "                    trig_off_time = np.concatenate((np.nan* np.ones(n_diff), trig_off_time))\n",
    "\n",
    "                n_scs = len(trig_on_time)\n",
    "                n_scs_imec[idx] = n_scs\n",
    "\n",
    "            elif n_trials_mk < n_scs: # more imec sample commands than mkturk trials\n",
    "                print('more imec trigs than mkturk trials')\n",
    "                n_diff=  n_scs - n_trials_mk  \n",
    "                t_diff_first = np.nansum(np.abs(sc_dur_mk/1000 - trig_dur[0:n_trials_mk]))\n",
    "                t_diff_last = np.nansum(np.abs(sc_dur_mk/1000-trig_dur[n_diff:n_scs]))\n",
    "                print(f'first {n_diff} trig :', trig_dur[0:n_diff], f'last {n_diff} trig : ', trig_dur[n_trials_mk:n_scs])\n",
    "                print(f'aligned to the first {n_trials_mk} imec trigs:', t_diff_first,f'aligned to the last {n_trials_mk} imec trigs:', t_diff_last)\n",
    "                if t_diff_first > 5 and t_diff_last > 5: # difference is more than 5 seconds \n",
    "                    print('difference is too big on both ends. Check trig_dur and sc_dur_mk')\n",
    "                    #print('imec trig : ', trig_dur, 'mkturk time : ', sc_dur_mk/1000)\n",
    "                    \n",
    "                    # sometimes mkturk sc is negative, and most of times this is why t_diff_first and t_diff_last is large \n",
    "                    print(len(np.where(sc_dur_mk <0)[0]), ' negative sc durations in mkturk file') \n",
    "                    ##### IMPORTANT! Sometimes there are 0s in imec trigger. See if removing these 0s help\n",
    "                    print(len(np.where(trig_dur==0)[0]), ' 0s found in imec trigger')\n",
    "                    if len(np.where(trig_dur==0)[0]) == n_diff: \n",
    "                        print(np.nansum(np.abs(sc_dur_mk/1000 - trig_dur[trig_dur!=0])), ' diff after removing 0s from imec trigger')\n",
    "\n",
    "                    #proceed_bool = input('proceed?')\n",
    "                if len(np.where(trig_dur==0)[0]) == n_diff: \n",
    "                    print('removing 0s from imec trigger')\n",
    "                    scs_ind = scs_ind[trig_dur !=0]\n",
    "                    trig_on_time = trig_on_time[trig_dur !=0]\n",
    "                    trig_off_time = trig_off_time[trig_dur !=0]\n",
    "                    trig_dur = trig_dur[trig_dur!=0]\n",
    "                else:\n",
    "                    if  t_diff_last > t_diff_first:\n",
    "                        scs_ind = scs_ind[0:n_trials_mk]\n",
    "                        trig_on_time = trig_on_time[0:n_trials_mk]\n",
    "                        trig_off_time = trig_off_time[0:n_trials_mk]\n",
    "                        # remove trials that are excess n_mk\n",
    "                        print(f'removing {n_scs-n_trials_mk} sample commands from the end')\n",
    "                    else:\n",
    "                        scs_ind = scs_ind[n_diff:n_scs]\n",
    "                        trig_on_time = trig_on_time[n_diff:n_scs]\n",
    "                        trig_off_time = trig_off_time[n_diff:n_scs]\n",
    "                        # remove trials that are excess n_mk\n",
    "                        print(f'removing {n_scs-n_trials_mk} sample commands from the beginning')\n",
    "                \n",
    "                scs_ind_imec[idx]= scs_ind\n",
    "                n_scs = len(scs_ind)\n",
    "                n_scs_imec[idx] = n_scs\n",
    "            \n",
    "            assert n_trials_mk == n_scs == len(trig_on_time) == len(trig_off_time)\n",
    "            trig_on_time = np.repeat(trig_on_time,n_rsvp)\n",
    "            trig_off_time = np.repeat(trig_off_time, n_rsvp)\n",
    "\n",
    "            for n_stim in data_dict:\n",
    "                data_dict[n_stim]['imec_trig_on'] = trig_on_time[n_stim]\n",
    "                data_dict[n_stim]['imec_trig_off'] = trig_off_time[n_stim]\n",
    "\n",
    "            # add short stim info \n",
    "            for n_stim in data_dict:\n",
    "                data_dict[n_stim]['stim_info_short'] = gen_short_scene_info(data_dict[n_stim]['stim_info'])\n",
    "                \n",
    "            # save out data_dict\n",
    "\n",
    "            save_out_file_name = 'data_dict_' + Path.Path(behav_file).stem\n",
    "            #pickle.dump(data_dict, open(save_out_path / save_out_file_name, 'wb'), protocol = 2)\n",
    "\n",
    "            data_dict_new = dict.fromkeys(range(n_stims_sess,len(data_dict)+n_stims_sess))\n",
    "            for n_stim in data_dict_new:\n",
    "                data_dict_new[n_stim] = data_dict[n_stim - n_stims_sess]\n",
    "                data_dict_new[n_stim]['trial_num'] = data_dict[n_stim-n_stims_sess]['trial_num']  + n_trials_sess\n",
    "            \n",
    "            data_dict_all = {**data_dict_all, **data_dict_new}\n",
    "            n_stims_sess += len(data_dict)\n",
    "            n_trials_sess += n_trials_mk\n",
    "            print(n_stims_sess)\n",
    "\n",
    "print('total # of stimulus presentations prepared in this session: ', n_stims_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_out_file_name = 'data_dict_' + data_path.name\n",
    "pickle.dump(data_dict_all, open(save_out_path / save_out_file_name, 'wb'), protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_dict\n",
    "del data_dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open(save_out_path / save_out_file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique stim info \n",
    "\n",
    "\n",
    "# get unique stims in the current session\n",
    "unique_stim = []\n",
    "stim_all = []\n",
    "stim_t_all = [] # (start, end) #\n",
    "stim_t_mk_all = []\n",
    "stim_present_bool = []\n",
    "stim_rsvp_num = []\n",
    "stim_trial_num = []\n",
    "reward_bool = []\n",
    "stim_scenefile = []\n",
    "stim_dur_all = []\n",
    "stim_iti_dur_all = []\n",
    "for n_stim in data_dict:\n",
    "    stim_all.append(data_dict[n_stim]['stim_info_short'])\n",
    "    stim_rsvp_num.append(data_dict[n_stim]['rsvp_num'])\n",
    "    stim_trial_num.append(data_dict[n_stim]['trial_num'])\n",
    "    reward_bool.append(data_dict[n_stim]['reward'])\n",
    "    \n",
    "    t_on_mk = data_dict[n_stim]['imec_trig_on'] + data_dict[n_stim]['t_mk']/1000 \n",
    "\n",
    "    \n",
    "    if type(data_dict[n_stim]['ph_t_rise']) == float: # if the photodiode is availalbe. Photodiode value is saved at the onset of first stimulus of a trial\n",
    "        t_on_ph = data_dict[n_stim]['imec_trig_on'] + data_dict[n_stim]['ph_t_rise']/1000 + np.unique(np.array(data_dict[n_stim]['stim_info'].loc[:,'dur'].tolist()))[0]/1000 * data_dict[n_stim]['rsvp_num'] \\\n",
    "                + data_dict[n_stim]['iti_dur']/1000 * data_dict[n_stim]['rsvp_num']\n",
    "    \n",
    "    else: \n",
    "        t_on_ph = np.nan\n",
    "\n",
    "    if data_dict[n_stim]['t_mk'] == -1:\n",
    "        stim_present_bool.append(0)\n",
    "    else:\n",
    "        stim_present_bool.append(1)\n",
    "\n",
    "    stim_t_mk_all.append(t_on_mk)\n",
    "    stim_t_all.append(t_on_ph) # 100 ms before the stimulus onset to end of stimulus + iti\n",
    "\n",
    "    stim_scenefile.append(data_dict[n_stim]['scenefile'])\n",
    "\n",
    "    if data_dict[n_stim]['stim_info_short'] not in unique_stim:\n",
    "        unique_stim.append(data_dict[n_stim]['stim_info_short'])\n",
    "\n",
    "    stim_dur_all.append(np.unique(np.array(data_dict[n_stim]['stim_info'].loc[:,'dur'].tolist()))[0]/1000)\n",
    "    stim_iti_dur_all.append(data_dict[n_stim]['iti_dur'])\n",
    "\n",
    "stim_t_all = np.array(stim_t_all)\n",
    "stim_t_mk_all = np.array(stim_t_mk_all)\n",
    "stim_present_bool = np.array(stim_present_bool)\n",
    "stim_rsvp_num = np.array(stim_rsvp_num)\n",
    "reward_bool = np.array(reward_bool)\n",
    "stim_scenefile = np.array(stim_scenefile)\n",
    "stim_dur_all = np.array(stim_dur_all)\n",
    "stim_trial_num = np.array(stim_trial_num)\n",
    "stim_iti_dur_all= np.array(stim_iti_dur_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_info_sess = dict.fromkeys(unique_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stim in unique_stim:\n",
    "    stim_info_sess[stim] = dict.fromkeys(['stim_ind', 't_on', 't_on_mk', 'dur', 'iti_dur','present_bool', 'rsvp_num', 'reward_bool', 'scenefile'])\n",
    "    stim_info_sess[stim]['stim_ind'] = np.where(np.array(stim_all) == stim)[0]\n",
    "    stim_info_sess[stim]['t_on_mk'] = stim_t_mk_all[stim_info_sess[stim]['stim_ind']] \n",
    "    stim_info_sess[stim]['t_on'] = stim_t_all[stim_info_sess[stim]['stim_ind']] #photodiode this should be default \n",
    "    stim_info_sess[stim]['dur'] = stim_dur_all[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['iti_dur'] = stim_iti_dur_all[stim_info_sess[stim]['stim_ind']]/1000\n",
    "    stim_info_sess[stim]['present_bool']= stim_present_bool[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['rsvp_num'] = stim_rsvp_num[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['trial_num'] = stim_trial_num[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['reward_bool'] = reward_bool[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['scenefile'] = stim_scenefile[stim_info_sess[stim]['stim_ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('# of unique stimulus prepared during the session: ', len(unique_stim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the stim info\n",
    "print(save_out_path)\n",
    "pickle.dump(stim_info_sess, open(save_out_path / 'stim_info_sess','wb'), protocol = 2 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
