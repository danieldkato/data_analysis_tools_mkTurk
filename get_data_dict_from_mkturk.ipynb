{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "from utils_meta import *\n",
    "from utils_mkturk import *\n",
    "import pathlib as Path\n",
    "import numpy as np \n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "from natsort import os_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  recordings found\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/West_20230914_R_H00_P07_AP-00.5_DV07.1_ML11.0_Ang90.2_Dep05541-05541_g0/West_20230914_R_H00_P07_AP-00.5_DV07.1_ML11.0_Ang90.2_Dep05541-05541_g0_imec0\n",
      "\n",
      "Data path found: True\n"
     ]
    }
   ],
   "source": [
    "# SET PATHS, RECORDING INFO\n",
    "#base_data_path = Path.Path(r'Z:\\Data')\n",
    "base_data_path = Path.Path('/Volumes/issa-locker/Data')\n",
    "\n",
    "monkey = 'West'\n",
    "date = '20230914'\n",
    "\n",
    "data_path = get_recording_path(base_data_path, monkey, date)\n",
    "\n",
    "n_recordings = len(data_path)\n",
    "print(n_recordings, ' recordings found')\n",
    "if n_recordings > 1:\n",
    "    data_ind = input('multiple recording sessions. Please select a number between 0 and' + str(len(data_path)-1))  # waiting for user input\n",
    "    data_path = Path.Path(data_path[int(data_ind)])\n",
    "else:\n",
    "    data_path = Path.Path(data_path[0])\n",
    "penetration = data_path.relative_to(base_data_path/monkey).as_posix().split('/')[0]\n",
    "print(data_path)\n",
    "\n",
    "print('\\nData path found: '+ str(data_path.exists()))\n",
    "\n",
    "# meta_iter = data_path.glob('*ap.meta')\n",
    "# bin_iter = data_path.glob('*ap.bin')   \n",
    "# meta_path = next(meta_iter)\n",
    "# bin_path = next(bin_iter) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/West_20230914_R_H00_P07_AP-00.5_DV07.1_ML11.0_Ang90.2_Dep05541-05541_g0/West_20230914_R_H00_P07_AP-00.5_DV07.1_ML11.0_Ang90.2_Dep05541-05541_g0_imec0/imec_trig\n",
      "3104\n"
     ]
    }
   ],
   "source": [
    "# get trig \n",
    "trig_path = data_path / 'imec_trig'\n",
    "print(trig_path)\n",
    "trig_on, trig_off = np.load(trig_path / 'trig_ind.npy')\n",
    "print(len(trig_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of behavior files in the data path:  14\n",
      "2023-09-14T17_12_30_West 123 123\n",
      "2023-09-14T17_20_02_West 217 217\n",
      "2023-09-14T17_29_06_West 208 208\n",
      "2023-09-14T17_38_38_West 206 206\n",
      "2023-09-14T17_48_08_West 204 204\n",
      "2023-09-14T17_58_02_West 204 204\n",
      "2023-09-14T18_07_49_West 255 255\n",
      "2023-09-14T18_21_58_West 203 203\n",
      "2023-09-14T18_32_28_West 399 399\n",
      "2023-09-14T18_54_22_West 206 206\n",
      "2023-09-14T19_16_34_West 213 213\n",
      "2023-09-14T19_38_15_West 224 224\n",
      "2023-09-14T19_53_06_West 225 225\n",
      "2023-09-14T20_06_42_West 126 126\n"
     ]
    }
   ],
   "source": [
    "# behavior files in the data path \n",
    "\n",
    "behav_file_list_orig = os_sorted(Path.Path(base_data_path, monkey, penetration).glob('*.json'))\n",
    "print('Number of behavior files in the data path: ', len(behav_file_list_orig)) \n",
    "for i, b_f in enumerate(behav_file_list_orig):\n",
    "    m = json.load(open(b_f, 'rb'))\n",
    "    n_trials_mk_prepared = len(m['TRIALEVENTS']['Sample']['0'])\n",
    "    if len(m['TRIALEVENTS']['TSequenceActualClip']) >  0:\n",
    "        n_trials_mk_shown = len(m['TRIALEVENTS']['TSequenceActualClip']['0'])\n",
    "    else:\n",
    "        n_trials_mk_shown = 0 \n",
    "    behav_file_list_orig[i] = b_f.as_posix()\n",
    "    print(b_f.stem, n_trials_mk_prepared, n_trials_mk_shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path exists\n",
      "/Volumes/issa-locker/users/Younah/ephys/West/West_20230914_R_H00_P07\n"
     ]
    }
   ],
   "source": [
    "if len(trig_on) > 1 and len(behav_file_list_orig) > 0:\n",
    "    save_out_root_path = '/Volumes/issa-locker/users/Younah/ephys/' + monkey\n",
    "    save_out_path = Path.Path(save_out_root_path, penetration)\n",
    "\n",
    "    if not os.path.exists(save_out_path):\n",
    "        os.mkdir(save_out_path)\n",
    "        print('creating save out folder')\n",
    "    else:\n",
    "        print('path exists')\n",
    "\n",
    "    if n_recordings> 1:\n",
    "        save_out_path = Path.Path(save_out_root_path, penetration, data_path.parts[len(data_path.parts)-2])\n",
    "\n",
    "    print(save_out_path)\n",
    "    os.makedirs(save_out_path, exist_ok=True)\n",
    "else:\n",
    "    print('Skip this recording session as there''s no trigger saved or behavior files not in the path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filecode(filecode_ind, len_filecode,out_list):\n",
    "    if len(filecode_ind) > len_filecode and len(filecode_ind) % len_filecode == 0:\n",
    "        # chunk by 6 \n",
    "        for i in range(0, len(filecode_ind), len_filecode):  \n",
    "            out_list.append(filecode_ind[i:i+len_filecode])\n",
    "    elif len(filecode_ind) == 6:\n",
    "        out_list.append(filecode_ind)\n",
    "    elif len(filecode_ind) > len_filecode: # if the detected \n",
    "        out_list.append(filecode_ind[len(filecode_ind)-len_filecode:len(filecode_ind)])\n",
    "    return out_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5] 6\n",
      "[129, 130, 131, 132, 133, 134] 6\n",
      "[352, 353, 354, 355, 356, 357] 6\n",
      "[566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577] 12\n",
      "[783, 784, 785, 786, 787, 788] 6\n",
      "[993, 994, 995, 996, 997, 998] 6\n",
      "[1203, 1204, 1205, 1206, 1207, 1208] 6\n",
      "[1464, 1465, 1466, 1467, 1468, 1469, 1470] 7\n",
      "[1674, 1675, 1676, 1677, 1678, 1679] 6\n",
      "[2079, 2080, 2081, 2082, 2083, 2084] 6\n",
      "[2291, 2292, 2293, 2294, 2295, 2296] 6\n",
      "[2510, 2511, 2512, 2513, 2514, 2515] 6\n",
      "[2740, 2741, 2742, 2743, 2744, 2745] 6\n",
      "[2972, 2973, 2974, 2975, 2976, 2977] 6\n",
      "[3103] 1\n",
      "15 possible filecodes found\n"
     ]
    }
   ],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "\n",
    "Fs = 30000\n",
    "len_filecode = 6\n",
    "max_trig_dur =300# digit (9 +1) * 10ms # change this value for earlier files. After 10/04/2023, 150 seems fine\n",
    "trig_dur = (trig_off - trig_on) /Fs * 1000 # ms\n",
    "ind = np.where(trig_dur <=max_trig_dur)[0] \n",
    "\n",
    "filecodes_ind_imec_possible= []\n",
    "for k, g in groupby(enumerate(ind), lambda ix : ix[0] -ix[1]):\n",
    "    filecode_ind = list(map(itemgetter(1), g))\n",
    "    print(filecode_ind, len(filecode_ind))\n",
    "    filecodes_ind_imec_possible = get_filecode(filecode_ind,len_filecode, filecodes_ind_imec_possible)\n",
    "print( f'{len(filecodes_ind_imec_possible)}' + ' possible filecodes found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 start ind:  0 filecode:  114_12_30 # of sample commands:  123\n",
      "1 start ind:  129 filecode:  27_20_02 # of sample commands:  217\n",
      "2 start ind:  352 filecode:  17_29_06 # of sample commands:  208\n",
      "3 start ind:  566 filecode:  101_71_47 # of sample commands:  0\n",
      "4 start ind:  572 filecode:  38_38_38 # of sample commands:  205\n",
      "5 start ind:  783 filecode:  17_59_08 # of sample commands:  204\n",
      "6 start ind:  993 filecode:  17_58_02 # of sample commands:  204\n",
      "7 start ind:  1203 filecode:  28_07_49 # of sample commands:  256\n",
      "8 start ind:  1465 filecode:  18_21_58 # of sample commands:  203\n",
      "9 start ind:  1674 filecode:  18_32_28 # of sample commands:  399\n",
      "10 start ind:  2079 filecode:  18_54_22 # of sample commands:  206\n",
      "11 start ind:  2291 filecode:  19_16_34 # of sample commands:  213\n",
      "12 start ind:  2510 filecode:  19_38_15 # of sample commands:  224\n",
      "13 start ind:  2740 filecode:  19_53_06 # of sample commands:  226\n",
      "14 start ind:  2972 filecode:  20_06_52 # of sample commands:  126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j2/nhpswgh91nl5_0rqnm305yrm0000gn/T/ipykernel_40596/2370646636.py:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  scs_ind_imec = np.array(scs_ind_imec)\n"
     ]
    }
   ],
   "source": [
    "filecodes_imec = []\n",
    "scs_ind_imec = []\n",
    "n_scs_imec = []\n",
    "filecodes_ind_imec = []\n",
    "\n",
    "for i, filecode_ind in enumerate(filecodes_ind_imec_possible):\n",
    "    assert len(filecode_ind) == len_filecode, f'filecode length is not {len_filecode}'\n",
    "\n",
    "    filecode_dur = trig_dur[filecode_ind]\n",
    "    # sc_ind corresponds to indices of sample command triggers followed by a filecode \n",
    "    if i == len(filecodes_ind_imec_possible) -1: \n",
    "        sc_ind = np.arange(filecode_ind[len_filecode-1]+1, len(trig_dur)) # sample commands followed by the last filecode within a session\n",
    "    else:\n",
    "        sc_ind = np.arange(filecode_ind[len_filecode-1]+1, filecodes_ind_imec_possible[i+1][0])\n",
    "\n",
    "    # number of sample commands or number of initated trials\n",
    "    n_scs = len(sc_ind)\n",
    "\n",
    "    # converting the digital filecode to timestamps which should match the name of the behavior file \n",
    "    f_convert =[round(f/10-1) for f in filecode_dur]\n",
    "    f_convert = [0 if x<0 else x for x in f_convert]\n",
    "\n",
    "    filecode = str(f_convert[0]) + str(f_convert[1]) + '_' + \\\n",
    "    str(f_convert[2]) + str(f_convert[3]) + '_' + \\\n",
    "    str(f_convert[4]) + str(f_convert[5]) \n",
    "\n",
    "    print(i, 'start ind: ', filecode_ind[0],'filecode: ', filecode, '# of sample commands: ', n_scs)\n",
    "    filecodes_imec.append(filecode)\n",
    "    scs_ind_imec.append(sc_ind)\n",
    "    n_scs_imec.append(n_scs)\n",
    "    filecodes_ind_imec.append(filecode_ind)\n",
    "\n",
    "filecodes_ind_imec = np.array(filecodes_ind_imec)\n",
    "scs_ind_imec = np.array(scs_ind_imec)\n",
    "n_scs_imec = np.array(n_scs_imec)\n",
    "filecodes_imec = np.array(filecodes_imec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 491.0333333333333\n",
      "2 500.6333333333334\n",
      "3 683.0666666666667\n",
      "5 477.0\n",
      "6 529.3\n",
      "7 508.03333333333336\n",
      "8 90881.26666666666\n",
      "9 565.0333333333334\n",
      "10 538.0666666666667\n",
      "11 323901.0333333333\n",
      "12 471.03333333333336\n",
      "13 484.20000000000005\n",
      "14 59023.53333333333\n"
     ]
    }
   ],
   "source": [
    "# there are some cases where the first sample command is fired before the filecode. \n",
    "# In this case, there is a very short latency between the onest of the filecode and the offset of the first sample command \n",
    "# it's likely that this first sample command was grouped to the previous file as the last sample command \n",
    "\n",
    "for idx,(filecode, filecode_ind, scs_ind) in enumerate(zip(filecodes_imec, filecodes_ind_imec,scs_ind_imec)):\n",
    "\n",
    "    if idx > 0 and n_scs_imec[idx-1] > 0:\n",
    "        t_diff = (trig_on[filecode_ind[0]] - trig_off[scs_ind_imec[idx-1][len(scs_ind_imec[idx-1])-1]]) /Fs * 1000\n",
    "        print(idx, t_diff)\n",
    "        if t_diff < 200: # less than 100ms or some small number\n",
    "            print(filecode)\n",
    "            prev_list= scs_ind_imec[idx-1]\n",
    "            scs_ind = np.insert(scs_ind, 0,prev_list[len(prev_list)-1])\n",
    "            scs_ind_imec[idx] = scs_ind\n",
    "            n_scs_imec[idx] = len(scs_ind)\n",
    "            scs_ind_imec[idx-1] = prev_list[0:len(prev_list)-1]\n",
    "            n_scs_imec[idx-1] = n_scs_imec[idx-1] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 filecode:  114_12_30  # of sample commands:  123 123\n",
      "1 filecode:  27_20_02  # of sample commands:  217 217\n",
      "2 filecode:  17_29_06  # of sample commands:  208 208\n",
      "3 filecode:  101_71_47  # of sample commands:  0 0\n",
      "4 filecode:  38_38_38  # of sample commands:  205 205\n",
      "5 filecode:  17_59_08  # of sample commands:  204 204\n",
      "6 filecode:  17_58_02  # of sample commands:  204 204\n",
      "7 filecode:  28_07_49  # of sample commands:  256 256\n",
      "8 filecode:  18_21_58  # of sample commands:  203 203\n",
      "9 filecode:  18_32_28  # of sample commands:  399 399\n",
      "10 filecode:  18_54_22  # of sample commands:  206 206\n",
      "11 filecode:  19_16_34  # of sample commands:  213 213\n",
      "12 filecode:  19_38_15  # of sample commands:  224 224\n",
      "13 filecode:  19_53_06  # of sample commands:  226 226\n",
      "14 filecode:  20_06_52  # of sample commands:  126 126\n"
     ]
    }
   ],
   "source": [
    "for i,(filecode, filecode_ind, scs_ind, n_scs) in enumerate(zip(filecodes_imec, filecodes_ind_imec, scs_ind_imec, n_scs_imec)):\n",
    "    print(i, 'filecode: ', filecode, ' # of sample commands: ', n_scs, len(scs_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "0 114_12_30\n",
      "# of scs:  123\n",
      "No corresponding behavior file that matches with filecode 114_12_30 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_12_30_West.json\n",
      "# of mkturk trials:  123\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "1 27_20_02\n",
      "# of scs:  217\n",
      "No corresponding behavior file that matches with filecode 27_20_02 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_20_02_West.json\n",
      "# of mkturk trials:  217\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "2 17_29_06\n",
      "# of scs:  208\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_29_06_West.json\n",
      "# of mkturk trials:  208\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "3 101_71_47\n",
      "# of scs:  0\n",
      "No corresponding behavior file that matches with filecode 101_71_47 from imec\n",
      "\n",
      "\n",
      "4 38_38_38\n",
      "# of scs:  205\n",
      "No corresponding behavior file that matches with filecode 38_38_38 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_38_38_West.json\n",
      "# of mkturk trials:  206\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "5 17_59_08\n",
      "# of scs:  204\n",
      "No corresponding behavior file that matches with filecode 17_59_08 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_48_08_West.json\n",
      "# of mkturk trials:  204\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "6 17_58_02\n",
      "# of scs:  204\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_58_02_West.json\n",
      "# of mkturk trials:  204\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "7 28_07_49\n",
      "# of scs:  256\n",
      "No corresponding behavior file that matches with filecode 28_07_49 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_07_49_West.json\n",
      "# of mkturk trials:  255\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "8 18_21_58\n",
      "# of scs:  203\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_21_58_West.json\n",
      "# of mkturk trials:  203\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "9 18_32_28\n",
      "# of scs:  399\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_32_28_West.json\n",
      "# of mkturk trials:  399\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "10 18_54_22\n",
      "# of scs:  206\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_54_22_West.json\n",
      "# of mkturk trials:  206\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "11 19_16_34\n",
      "# of scs:  213\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_16_34_West.json\n",
      "# of mkturk trials:  213\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "12 19_38_15\n",
      "# of scs:  224\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_38_15_West.json\n",
      "# of mkturk trials:  224\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "13 19_53_06\n",
      "# of scs:  226\n",
      "matching behavior file found\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_53_06_West.json\n",
      "# of mkturk trials:  225\n",
      "RewardStage :  1\n",
      "\n",
      "\n",
      "14 20_06_52\n",
      "# of scs:  126\n",
      "No corresponding behavior file that matches with filecode 20_06_52 from imec\n",
      "filecode is defective but matches most of the datetime string in the behavior file\n",
      "matched with /Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T20_06_42_West.json\n",
      "# of mkturk trials:  126\n",
      "RewardStage :  1\n"
     ]
    }
   ],
   "source": [
    "# Matching behavior file to imec filecode \n",
    "\n",
    "behav_file_list = []\n",
    "behav_file_list_idx = [-1]\n",
    "filecodes_imec_to_analyze = []\n",
    "scs_ind_imec_to_analyze = []\n",
    "n_scs_imec_to_analyze = []\n",
    "filecodes_ind_imec_to_analyze = []\n",
    "for i, (f, n_scs, scs_ind, filecodes_ind) in enumerate(zip(filecodes_imec, n_scs_imec,scs_ind_imec,filecodes_ind_imec)):\n",
    "    print('\\n')\n",
    "    print(i, f)\n",
    "    print('# of scs: ', n_scs)\n",
    "    \n",
    "    behav_file = os_sorted(Path.Path(base_data_path, monkey, penetration).glob('*' + f + '*.json'))\n",
    "    if len(behav_file) > 0:\n",
    "        m = json.load(open(behav_file[0].as_posix(),'rb'))\n",
    "        if len(m['TRIALEVENTS']['TSequenceActualClip']) >  0:\n",
    "            n_trials_mk = len(m['TRIALEVENTS']['TSequenceActualClip']['0'])\n",
    "        else:\n",
    "            n_trials_mk = 0 \n",
    "\n",
    "        print('matching behavior file found')\n",
    "        print('matched with' , behav_file[0].as_posix())\n",
    "        print('# of mkturk trials: ', n_trials_mk)\n",
    "        print('RewardStage : ', m['TASK']['RewardStage'])\n",
    "\n",
    "        behav_file_list.append(behav_file[0].as_posix())\n",
    "        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == behav_file[0].as_posix())[0])\n",
    "        filecodes_imec_to_analyze.append(f)\n",
    "        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "        n_scs_imec_to_analyze.append(n_scs)\n",
    "        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "    else:\n",
    "        print(f'No corresponding behavior file that matches with filecode {f} from imec' )\n",
    "\n",
    "        # if there exists a mkturk file that matches almost all of the filecodes\n",
    "        for b_f_idx, b_f in enumerate(behav_file_list_orig):\n",
    "            if b_f not in behav_file_list and b_f_idx > max(behav_file_list_idx):\n",
    "                m = json.load(open(b_f,'rb'))\n",
    "                if len(m['TRIALEVENTS']['TSequenceActualClip']) >  0:\n",
    "                    n_trials_mk = len(m['TRIALEVENTS']['TSequenceActualClip']['0'])\n",
    "                else:\n",
    "                    n_trials_mk = 0 \n",
    "\n",
    "                file_time = Path.Path(b_f).stem.split('T')[1].split('_' + monkey)[0]\n",
    "                file_time_txt = file_time.split('_')\n",
    "                file_time_hour = file_time_txt[0]\n",
    "                file_time_minute = file_time_txt[1]\n",
    "                file_time_second = file_time_txt[2]\n",
    "\n",
    "                f_txt = f.split('_')\n",
    "                f_hour = f_txt[0]\n",
    "                f_minute = f_txt[1]\n",
    "                f_second = f_txt[2]\n",
    "\n",
    "                hour_diff = abs(int(file_time_hour) - int(f_hour))\n",
    "                minute_diff = abs(int(file_time_minute) - int(f_minute))\n",
    "                second_diff = abs(int(file_time_second) - int(f_second))\n",
    "                \n",
    "                diff_all = np.array((hour_diff,minute_diff,second_diff))\n",
    "\n",
    "                str_match =0\n",
    "\n",
    "                for t_str_count in range(8):\n",
    "                    if file_time[t_str_count] == f[t_str_count]:\n",
    "                        str_match += 1\n",
    "\n",
    "                if sum(diff_all) <=3 or len(np.where(diff_all == 0)[0]) == 2 or str_match >=6:\n",
    "                #if str_match >=6: # you can relax this threshold by making this number smaller\n",
    "                    print('filecode is defective but matches most of the datetime string in the behavior file')\n",
    "                    print('matched with' , b_f)\n",
    "                    print('# of mkturk trials: ', n_trials_mk)\n",
    "                    print('RewardStage : ', m['TASK']['RewardStage'])\n",
    "                    if n_scs == 0 and m['TASK']['RewardStage'] == 0:\n",
    "                        behav_file_list.append(b_f)\n",
    "                        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == b_f)[0])\n",
    "                        filecodes_imec_to_analyze.append(f)\n",
    "                        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "                        n_scs_imec_to_analyze.append(n_scs)\n",
    "                        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "                        break \n",
    "                    elif abs(n_scs - n_trials_mk) < 7:\n",
    "                        behav_file_list.append(b_f)\n",
    "                        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == b_f)[0])\n",
    "                        filecodes_imec_to_analyze.append(f)\n",
    "                        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "                        n_scs_imec_to_analyze.append(n_scs)\n",
    "                        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "                        break \n",
    "                    else:\n",
    "                        print('# of sc and # of mk trials don''t match up')\n",
    "                        break\n",
    "                else:\n",
    "\n",
    "                    if n_trials_mk >= n_scs -2 and n_trials_mk <= n_scs + 2 and n_scs !=0: # this might happen for earlier files \n",
    "\n",
    "                        print('no string matched but the number of sample command triggers seem to match the number of mkturk trials')\n",
    "                        print('# of mkturk trials: ', n_trials_mk)\n",
    "                        print('matched with' , b_f)\n",
    "                        print('RewardStage : ', m['TASK']['RewardStage'])\n",
    "\n",
    "                        behav_file_list.append(b_f)\n",
    "                        behav_file_list_idx.append(np.where(np.array(behav_file_list_orig) == b_f)[0])\n",
    "                        filecodes_imec_to_analyze.append(f)\n",
    "                        scs_ind_imec_to_analyze.append(scs_ind)\n",
    "                        n_scs_imec_to_analyze.append(n_scs)\n",
    "                        filecodes_ind_imec_to_analyze.append(filecodes_ind)\n",
    "\n",
    "                        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(behav_file_list) == len(n_scs_imec_to_analyze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  behavior files are unmatched \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(behav_file_list_orig) - len(behav_file_list), ' behavior files are unmatched \\n')\n",
    "unmatched_behav_file = list(set(behav_file_list_orig) - set(behav_file_list))\n",
    "\n",
    "for b_f in unmatched_behav_file:\n",
    "    print(b_f)\n",
    "    m = json.load(open(b_f,'rb'))\n",
    "    print('RewardStage : ', m['TASK']['RewardStage'], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "# You can either try to find triggers that belong to this remaining behavior file \n",
    "#  or skip it if it's a calibration file \n",
    "\n",
    "# of trigs unaccounted for \n",
    "print(len(trig_on) - (np.sum(n_scs_imec_to_analyze) + len_filecode * len(filecodes_imec_to_analyze)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_12_30_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_0ABCDEFGHI.json']\n",
      "# of trials from mkturk file : 123 \n",
      "# of imec triggers :  123\n",
      "mean trig dur:  1.5267715447154477 sd:  0.1261489987867664\n",
      "# of mkturk trials matches # of imec trigs\n",
      "386.3606333333335\n",
      "369\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_20_02_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1AXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_1XBC.json']\n",
      "# of trials from mkturk file : 217 \n",
      "# of imec triggers :  217\n",
      "mean trig dur:  1.5760075268817224 sd:  0.1438159182451059\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.10470000000149171\n",
      "1020\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_29_06_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1XXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_0ABC.json']\n",
      "# of trials from mkturk file : 208 \n",
      "# of imec triggers :  208\n",
      "mean trig dur:  1.567624358974358 sd:  0.14878452201076606\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.10313333333560482\n",
      "1644\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_38_38_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1ABC.json', '/mkturkfiles/scenebags/West/neural_stim_3_2DEF.json']\n",
      "# of trials from mkturk file : 206 \n",
      "# of imec triggers :  205\n",
      "mean trig dur:  1.5856305691056916 sd:  0.15701433127399608\n",
      "more mkturk trials than imec trigs\n",
      "first 1 mkturk trials :  [-30.]  last 1 mkturk trials:  [1516.]\n",
      "aligned to the first 205 mkturk trials:  142.4074666666672  aligned to the last 205 mkturk trials:  107.87013333333499\n",
      "difference is too big on both ends. Check trig_dur and sc_dur_mk. If trig_dur is fine, proceed\n",
      "2  negative sc durations in mkturk file\n",
      "adds nan values at the beginning of imec trigger\n",
      "2262\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_48_08_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1AXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_1XBC.json']\n",
      "# of trials from mkturk file : 204 \n",
      "# of imec triggers :  204\n",
      "mean trig dur:  1.5781156862744932 sd:  0.14590943543414947\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.09173333333760314\n",
      "2874\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T17_58_02_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1XXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_0ABC.json']\n",
      "# of trials from mkturk file : 204 \n",
      "# of imec triggers :  204\n",
      "mean trig dur:  1.5874442810457625 sd:  0.16068859190218024\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.0947000000066327\n",
      "3486\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_07_49_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1ABC.json', '/mkturkfiles/scenebags/West/neural_stim_3_2DEF.json']\n",
      "# of trials from mkturk file : 255 \n",
      "# of imec triggers :  256\n",
      "mean trig dur:  1.5617527343750055 sd:  0.16799407518743217\n",
      "more imec trigs than mkturk trials\n",
      "first 1 trig : [1.98366667] last 1 trig :  [0.28836667]\n",
      "aligned to the first 255 imec trigs: 0.14806666667626134 aligned to the last 255 imec trigs: 39.144300000003156\n",
      "removing 1 sample commands from the end\n",
      "4251\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_21_58_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1AXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_1XBC.json']\n",
      "# of trials from mkturk file : 203 \n",
      "# of imec triggers :  203\n",
      "mean trig dur:  1.546676518883431 sd:  0.13351060154139993\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.08060000001040968\n",
      "4860\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_32_28_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1XXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_0ABC.json']\n",
      "# of trials from mkturk file : 399 \n",
      "# of imec triggers :  399\n",
      "mean trig dur:  1.5632458646616538 sd:  0.13401192825050143\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.1774333333584328\n",
      "6057\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T18_54_22_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1ABC.json', '/mkturkfiles/scenebags/West/neural_stim_3_2DEF.json']\n",
      "# of trials from mkturk file : 206 \n",
      "# of imec triggers :  206\n",
      "mean trig dur:  1.5565300970873475 sd:  0.15630703741793245\n",
      "# of mkturk trials matches # of imec trigs\n",
      "267.55686666668055\n",
      "6675\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_16_34_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1AXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_1XBC.json']\n",
      "# of trials from mkturk file : 213 \n",
      "# of imec triggers :  213\n",
      "mean trig dur:  1.530444444444387 sd:  0.14661124428262748\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.08620000001422823\n",
      "7314\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_38_15_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1ABC.json', '/mkturkfiles/scenebags/West/neural_stim_3_2DEF.json']\n",
      "# of trials from mkturk file : 224 \n",
      "# of imec triggers :  224\n",
      "mean trig dur:  1.5678616071428613 sd:  0.15984380655581132\n",
      "# of mkturk trials matches # of imec trigs\n",
      "0.10173333335242862\n",
      "7986\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T19_53_06_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_1XXX.json', '/mkturkfiles/scenebags/West/neural_stim_3_0ABC.json']\n",
      "# of trials from mkturk file : 225 \n",
      "# of imec triggers :  226\n",
      "mean trig dur:  1.5387153392330863 sd:  0.1355168768247431\n",
      "more imec trigs than mkturk trials\n",
      "first 1 trig : [1.518] last 1 trig :  [1.35273333]\n",
      "aligned to the first 225 imec trigs: 0.10433333335740969 aligned to the last 225 imec trigs: 32.102399999992315\n",
      "removing 1 sample commands from the end\n",
      "8661\n",
      "/Volumes/issa-locker/Data/West/West_20230914_R_H00_P07/2023-09-14T20_06_42_West.json\n",
      "['/mkturkfiles/scenebags/West/neural_stim_3_0ABCDEFGHI.json']\n",
      "# of trials from mkturk file : 126 \n",
      "# of imec triggers :  126\n",
      "mean trig dur:  1.516916666666706 sd:  0.17206537633870478\n",
      "# of mkturk trials matches # of imec trigs\n",
      "75.64483333333918\n",
      "9039\n",
      "total # of stimulus presentations prepared in this session:  9039\n"
     ]
    }
   ],
   "source": [
    "n_stims_sess = 0 \n",
    "n_trials_sess = 0\n",
    "data_dict_all = dict()\n",
    "for idx, (behav_file, scs_ind, n_scs,filecode_ind) in enumerate(zip(behav_file_list,scs_ind_imec_to_analyze, n_scs_imec_to_analyze,filecodes_ind_imec_to_analyze)):\n",
    "    print(behav_file)\n",
    "    # skip calibration files\n",
    "    m = json.load(open(behav_file,'rb'))\n",
    "\n",
    "    if m['TASK']['RewardStage'] == 0:\n",
    "        print('calibration file. removing it from further analysis')\n",
    "    else:\n",
    "        if len(m['TASK']['ImageBagsSample']) != len( m['SCENES']['SampleScenes']):\n",
    "            print('ImageBagSample and number of scenefiles don''t match. skip this behavior file')\n",
    "            continue\n",
    "\n",
    "        data_dict  = create_data_mat(behav_file)\n",
    "        print(m['TASK']['ImageBagsSample'])\n",
    "\n",
    "        sc_off_mk =np.array(m['TRIALEVENTS']['SampleCommandOffReturnTime'],dtype=float)\n",
    "        sc_on_mk = np.array(m['TRIALEVENTS']['SampleCommandReturnTime'],dtype=float)\n",
    "\n",
    "        n_rsvp = m['TASK']['NRSVP']\n",
    "\n",
    "        trig_on_time = trig_on[scs_ind]/Fs \n",
    "        trig_off_time = trig_off[scs_ind]/Fs \n",
    "        trig_dur = trig_off_time - trig_on_time\n",
    "\n",
    "        if len(sc_on_mk) != len(sc_off_mk):\n",
    "            print('mkturk behavior file has mismatched sample command on and off ')\n",
    "            if sc_on_mk[0] < sc_off_mk[0] and len(sc_on_mk) > len(sc_off_mk):\n",
    "                sc_off_mk = np.concatenate((sc_off_mk,np.nan * np.ones(len(sc_on_mk) - len(sc_off_mk))))\n",
    "                \n",
    "        sc_dur_mk =sc_off_mk - sc_on_mk\n",
    "        n_trials_mk = len(sc_dur_mk)\n",
    "\n",
    "        print('# of trials from mkturk file :', n_trials_mk, '\\n'\n",
    "            '# of imec triggers : ', n_scs)\n",
    "        \n",
    "        if n_trials_mk <= 10 and n_scs <= 10:\n",
    "            print('two few trials. Removing it from further analysis')\n",
    "        else:   \n",
    "            # compare number of triggers from imec file and n_trials_mk\n",
    "            # if they mismatch, they usually mismatch by 1\n",
    "            mean = np.mean(trig_dur)\n",
    "            sd = np.std(trig_dur)\n",
    "            print('mean trig dur: ', mean, 'sd: ', sd)\n",
    "            \n",
    "            if n_trials_mk == n_scs: \n",
    "                print('# of mkturk trials matches # of imec trigs')\n",
    "                print(np.nansum(np.abs(sc_dur_mk/1000 - trig_dur)))  # this number should be small but sometimes mkturk SampleCommandOffReturnTime is weird\n",
    "                #print(trig_dur, sc_dur_mk)\n",
    "            \n",
    "            if n_trials_mk > n_scs: # more mkturk trials than imec sample commands\n",
    "                print('more mkturk trials than imec trigs')\n",
    "                n_diff= n_trials_mk - n_scs\n",
    "                t_diff_first = np.nansum(np.abs(sc_dur_mk[0:n_scs]/1000 - trig_dur))\n",
    "                t_diff_last = np.nansum(np.abs(sc_dur_mk[n_diff:n_trials_mk]/1000-trig_dur))\n",
    "                print(f'first {n_diff} mkturk trials : ', sc_dur_mk[0:n_diff], f' last {n_diff} mkturk trials: ', sc_dur_mk[n_scs:n_trials_mk])\n",
    "                print(f'aligned to the first {n_scs} mkturk trials: ', t_diff_first, f' aligned to the last {n_scs} mkturk trials: ', t_diff_last)\n",
    "                \n",
    "                if t_diff_first > 5 and t_diff_last > 5:\n",
    "                    print('difference is too big on both ends. Check trig_dur and sc_dur_mk. If trig_dur is fine, proceed')\n",
    "                    #print('imec trig : ', trig_dur, 'mkturk time : ', sc_dur_mk/1000)\n",
    "                    print(len(np.where(sc_dur_mk <0)[0]), ' negative sc durations in mkturk file') \n",
    "\n",
    "                if t_diff_first < t_diff_last:\n",
    "                    # adds nan value at the end of imec trigger\n",
    "                    print('adds nan values at the end of imec trigger')\n",
    "                    trig_on_time = np.concatenate((trig_on_time,np.nan* np.ones(n_diff)))\n",
    "                    trig_off_time = np.concatenate((trig_off_time,np.nan* np.ones(n_diff)))\n",
    "                else:\n",
    "                    # adds nan value at the beginning of imec trigger\n",
    "                    print('adds nan values at the beginning of imec trigger')\n",
    "                    trig_on_time = np.concatenate((np.nan* np.ones(n_diff), trig_on_time))\n",
    "                    trig_off_time = np.concatenate((np.nan* np.ones(n_diff), trig_off_time))\n",
    "\n",
    "                n_scs = len(trig_on_time)\n",
    "                n_scs_imec[idx] = n_scs\n",
    "\n",
    "            elif n_trials_mk < n_scs: # more imec sample commands than mkturk trials\n",
    "                print('more imec trigs than mkturk trials')\n",
    "                n_diff=  n_scs - n_trials_mk  \n",
    "                t_diff_first = np.nansum(np.abs(sc_dur_mk/1000 - trig_dur[0:n_trials_mk]))\n",
    "                t_diff_last = np.nansum(np.abs(sc_dur_mk/1000-trig_dur[n_diff:n_scs]))\n",
    "                print(f'first {n_diff} trig :', trig_dur[0:n_diff], f'last {n_diff} trig : ', trig_dur[n_trials_mk:n_scs])\n",
    "                print(f'aligned to the first {n_trials_mk} imec trigs:', t_diff_first,f'aligned to the last {n_trials_mk} imec trigs:', t_diff_last)\n",
    "                if t_diff_first > 5 and t_diff_last > 5: # difference is more than 5 seconds \n",
    "                    print('difference is too big on both ends. Check trig_dur and sc_dur_mk')\n",
    "                    #print('imec trig : ', trig_dur, 'mkturk time : ', sc_dur_mk/1000)\n",
    "                    \n",
    "                    # sometimes mkturk sc is negative, and most of times this is why t_diff_first and t_diff_last is large \n",
    "                    print(len(np.where(sc_dur_mk <0)[0]), ' negative sc durations in mkturk file') \n",
    "                    ##### IMPORTANT! Sometimes there are 0s in imec trigger. See if removing these 0s help\n",
    "                    print(len(np.where(trig_dur==0)[0]), ' 0s found in imec trigger')\n",
    "                    if len(np.where(trig_dur==0)[0]) == n_diff: \n",
    "                        print(np.nansum(np.abs(sc_dur_mk/1000 - trig_dur[trig_dur!=0])), ' diff after removing 0s from imec trigger')\n",
    "\n",
    "                    #proceed_bool = input('proceed?')\n",
    "                if len(np.where(trig_dur==0)[0]) == n_diff: \n",
    "                    print('removing 0s from imec trigger')\n",
    "                    scs_ind = scs_ind[trig_dur !=0]\n",
    "                    trig_on_time = trig_on_time[trig_dur !=0]\n",
    "                    trig_off_time = trig_off_time[trig_dur !=0]\n",
    "                    trig_dur = trig_dur[trig_dur!=0]\n",
    "                else:\n",
    "                    if  t_diff_last > t_diff_first:\n",
    "                        scs_ind = scs_ind[0:n_trials_mk]\n",
    "                        trig_on_time = trig_on_time[0:n_trials_mk]\n",
    "                        trig_off_time = trig_off_time[0:n_trials_mk]\n",
    "                        # remove trials that are excess n_mk\n",
    "                        print(f'removing {n_scs-n_trials_mk} sample commands from the end')\n",
    "                    else:\n",
    "                        scs_ind = scs_ind[n_diff:n_scs]\n",
    "                        trig_on_time = trig_on_time[n_diff:n_scs]\n",
    "                        trig_off_time = trig_off_time[n_diff:n_scs]\n",
    "                        # remove trials that are excess n_mk\n",
    "                        print(f'removing {n_scs-n_trials_mk} sample commands from the beginning')\n",
    "                \n",
    "                scs_ind_imec[idx]= scs_ind\n",
    "                n_scs = len(scs_ind)\n",
    "                n_scs_imec[idx] = n_scs\n",
    "            \n",
    "            assert n_trials_mk == n_scs == len(trig_on_time) == len(trig_off_time)\n",
    "            trig_on_time = np.repeat(trig_on_time,n_rsvp)\n",
    "            trig_off_time = np.repeat(trig_off_time, n_rsvp)\n",
    "\n",
    "            for n_stim in data_dict:\n",
    "                data_dict[n_stim]['imec_trig_on'] = trig_on_time[n_stim]\n",
    "                data_dict[n_stim]['imec_trig_off'] = trig_off_time[n_stim]\n",
    "\n",
    "            # add short stim info \n",
    "            for n_stim in data_dict:\n",
    "                data_dict[n_stim]['stim_info_short'] = gen_short_scene_info(data_dict[n_stim]['stim_info'])\n",
    "                \n",
    "            # save out data_dict\n",
    "\n",
    "            save_out_file_name = 'data_dict_' + Path.Path(behav_file).stem\n",
    "            pickle.dump(data_dict, open(save_out_path / save_out_file_name, 'wb'), protocol = 2)\n",
    "\n",
    "            data_dict_new = dict.fromkeys(range(n_stims_sess,len(data_dict)+n_stims_sess))\n",
    "            for n_stim in data_dict_new:\n",
    "                data_dict_new[n_stim] = data_dict[n_stim - n_stims_sess]\n",
    "                data_dict_new[n_stim]['trial_num'] = data_dict[n_stim-n_stims_sess]['trial_num']  + n_trials_sess\n",
    "            \n",
    "            data_dict_all = {**data_dict_all, **data_dict_new}\n",
    "            n_stims_sess += len(data_dict)\n",
    "            n_trials_sess += n_trials_mk\n",
    "            print(n_stims_sess)\n",
    "\n",
    "print('total # of stimulus presentations prepared in this session: ', n_stims_sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_out_file_name = 'data_dict_' + data_path.name\n",
    "pickle.dump(data_dict_all, open(save_out_path / save_out_file_name, 'wb'), protocol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_dict\n",
    "del data_dict_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = pickle.load(open(save_out_path / save_out_file_name, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique stim info \n",
    "\n",
    "\n",
    "# get unique stims in the current session\n",
    "unique_stim = []\n",
    "stim_all = []\n",
    "stim_t_all = [] # (start, end) #\n",
    "stim_t_mk_all = []\n",
    "stim_present_bool = []\n",
    "stim_rsvp_num = []\n",
    "stim_trial_num = []\n",
    "reward_bool = []\n",
    "stim_scenefile = []\n",
    "stim_dur_all = []\n",
    "stim_iti_dur_all = []\n",
    "for n_stim in data_dict:\n",
    "    stim_all.append(data_dict[n_stim]['stim_info_short'])\n",
    "    stim_rsvp_num.append(data_dict[n_stim]['rsvp_num'])\n",
    "    stim_trial_num.append(data_dict[n_stim]['trial_num'])\n",
    "    reward_bool.append(data_dict[n_stim]['reward'])\n",
    "    \n",
    "    t_on_mk = data_dict[n_stim]['imec_trig_on'] + data_dict[n_stim]['t_mk']/1000 \n",
    "\n",
    "    \n",
    "    if type(data_dict[n_stim]['ph_t_rise']) == float: # if the photodiode is availalbe. Photodiode value is saved at the onset of first stimulus of a trial\n",
    "        t_on_ph = data_dict[n_stim]['imec_trig_on'] + data_dict[n_stim]['ph_t_rise']/1000 + np.unique(np.array(data_dict[n_stim]['stim_info'].loc[:,'dur'].tolist()))[0]/1000 * data_dict[n_stim]['rsvp_num'] \\\n",
    "                + data_dict[n_stim]['iti_dur']/1000 * data_dict[n_stim]['rsvp_num']\n",
    "    \n",
    "    else: \n",
    "        t_on_ph = np.nan\n",
    "\n",
    "    if data_dict[n_stim]['t_mk'] == -1:\n",
    "        stim_present_bool.append(0)\n",
    "    else:\n",
    "        stim_present_bool.append(1)\n",
    "\n",
    "    stim_t_mk_all.append(t_on_mk)\n",
    "    stim_t_all.append(t_on_ph) # 100 ms before the stimulus onset to end of stimulus + iti\n",
    "\n",
    "    stim_scenefile.append(data_dict[n_stim]['scenefile'])\n",
    "\n",
    "    if data_dict[n_stim]['stim_info_short'] not in unique_stim:\n",
    "        unique_stim.append(data_dict[n_stim]['stim_info_short'])\n",
    "\n",
    "    stim_dur_all.append(np.unique(np.array(data_dict[n_stim]['stim_info'].loc[:,'dur'].tolist()))[0]/1000)\n",
    "    stim_iti_dur_all.append(data_dict[n_stim]['iti_dur'])\n",
    "\n",
    "stim_t_all = np.array(stim_t_all)\n",
    "stim_t_mk_all = np.array(stim_t_mk_all)\n",
    "stim_present_bool = np.array(stim_present_bool)\n",
    "stim_rsvp_num = np.array(stim_rsvp_num)\n",
    "reward_bool = np.array(reward_bool)\n",
    "stim_scenefile = np.array(stim_scenefile)\n",
    "stim_dur_all = np.array(stim_dur_all)\n",
    "stim_trial_num = np.array(stim_trial_num)\n",
    "stim_iti_dur_all= np.array(stim_iti_dur_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_info_sess = dict.fromkeys(unique_stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stim in unique_stim:\n",
    "    stim_info_sess[stim] = dict.fromkeys(['stim_ind', 't_on', 't_on_mk', 'dur', 'iti_dur','present_bool', 'rsvp_num', 'reward_bool', 'scenefile'])\n",
    "    stim_info_sess[stim]['stim_ind'] = np.where(np.array(stim_all) == stim)[0]\n",
    "    stim_info_sess[stim]['t_on_mk'] = stim_t_mk_all[stim_info_sess[stim]['stim_ind']] \n",
    "    stim_info_sess[stim]['t_on'] = stim_t_all[stim_info_sess[stim]['stim_ind']] #photodiode this should be default \n",
    "    stim_info_sess[stim]['dur'] = stim_dur_all[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['iti_dur'] = stim_iti_dur_all[stim_info_sess[stim]['stim_ind']]/1000\n",
    "    stim_info_sess[stim]['present_bool']= stim_present_bool[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['rsvp_num'] = stim_rsvp_num[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['trial_num'] = stim_trial_num[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['reward_bool'] = reward_bool[stim_info_sess[stim]['stim_ind']]\n",
    "    stim_info_sess[stim]['scenefile'] = stim_scenefile[stim_info_sess[stim]['stim_ind']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of unique stimulus prepared during the session:  201\n"
     ]
    }
   ],
   "source": [
    "print ('# of unique stimulus prepared during the session: ', len(unique_stim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Volumes/issa-locker/users/Younah/ephys/West/West_20230914_R_H00_P07\n"
     ]
    }
   ],
   "source": [
    "# save the stim info\n",
    "print(save_out_path)\n",
    "pickle.dump(stim_info_sess, open(save_out_path / 'stim_info_sess','wb'), protocol = 2 )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
